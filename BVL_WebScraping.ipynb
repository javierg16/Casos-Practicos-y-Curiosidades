{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EL CÓDIGO CONSISTE DE DOS PARTES:\n",
    "##### 1. OBTENER EL MOVIMIENTO DIARIO DE LAS ACCIONES \n",
    "##### BAJO EL TÍTULO: \"WEB SCRAPING DE LOS MOVIMIENTOS DIARIOS DE LA BVL\"\n",
    "##### 2. OBTENER LA INFORMACIÓN FINANCIERA DE LAS EMPRESAS LISTADAS EN LA BVL (LAS QUE ESCOJA)\n",
    "##### BAJO EL TÍTULO: \"WEB SCRAPING DE LOS ESTADOS FINANCIEROS DE UNA EMPRESA PERUANA DE LA BVL\"\n",
    "########## NOTA 1: DEBE TOMAR EN CUENTA QUE LAS PÁGINAS ESTÁN SUJETAS A CAMBIOS,\n",
    "########## POR LO QUE EN EL FUTURO EL CÓDIGO PODRÍA REQUERIR CIERTAS VARIACIONES\n",
    "########## NOTA 2: ALGUNOS PROCESOS TOMAN CIERTO TIEMPO PARA GARANTIZAR UNA CORRECTA EXTRACCIÓN DE DATOS.\n",
    "########## NOTA 3: ESTE ES UN CÓDIGO LIBRE ( YA SEA COMO MATERIAL DE APRENDIZAJE O SI DESEA REALIZAR SU PROPIA VERSIÓN)\n",
    "########## NOTA 4: SIEMPRE HAY ESPACIO PARA MEJORAS Y ACTUALIZACIONES\n",
    "########## NOTA 5: ASEGÚRESE DE SEGUIR LAS INTRUCCIONES Y TOMAR EN CUENTA LOS COMENTARIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873de270",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS MOVIMIENTOS DIARIOS DE LA BVL ########\n",
    "\n",
    "#Primero obtendremos el html de la tabla que contiene los datos\n",
    "#Importando las librerías necesarias\n",
    "#En caso no se tengan las librerías instalarlas\n",
    "#pip install BeautifulSoup\n",
    "#pip install selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import time\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# Inicializar el controlador de Selenium\n",
    "driver = webdriver.Chrome('/path/to/chromedriver') # Reemplazar con la ruta al controlador de Chrome\n",
    "\n",
    "# Abrir la página web\n",
    "url = \"https://www.bvl.com.pe/mercado/movimientos-diarios\"\n",
    "driver.get(url)\n",
    "\n",
    "# Esperar a que cargue la página, 10 segundos es prudente\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"table-dark\")))\n",
    "\n",
    "# Obtener el HTML de la página\n",
    "html = driver.page_source\n",
    "\n",
    "# Analizar el HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Encontrar la tabla en el HTML\n",
    "tabla = soup.find(\"table\", {\"class\": \"table-dark\"})\n",
    "\n",
    "# Imprimir la tabla\n",
    "print(tabla)\n",
    "\n",
    "# Cerrar el controlador de Selenium\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5acae4c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Obtenemos las filas dentro de la tabla y el número\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m filas \u001b[38;5;241m=\u001b[39m \u001b[43mtabla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbvl-row\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#print(filas) #se puede imprimir el html en caso de querer revisarlo\u001b[39;00m\n\u001b[0;32m      4\u001b[0m num_filas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(filas)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\element.py:2289\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   2288\u001b[0m     \u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[0;32m   2291\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "####### WEB SCRAPING DE LOS MOVIMIENTOS DIARIOS DE LA BVL ########\n",
    "\n",
    "#Obtenemos las filas dentro de la tabla y el número\n",
    "filas = tabla.find_all('tr', {'class': 'bvl-row'})\n",
    "#print(filas) #se puede imprimir el html en caso de querer revisarlo\n",
    "num_filas=len(filas)-1\n",
    "print(num_filas)\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS MOVIMIENTOS DIARIOS DE LA BVL ########\n",
    "\n",
    "#Primero extraemos el encabezado y el número de columnas\n",
    "valores=filas[0].find_all('th', {'class': 'bvl-header-cell'})\n",
    "columnas=len(valores)-1\n",
    "print(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df37a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS MOVIMIENTOS DIARIOS DE LA BVL ########\n",
    "\n",
    "#1era opción: Guardar los datos en un CSV\n",
    "with open('Daily_Movements_BVL.csv', 'w', encoding='utf8', newline='') as f:\n",
    "    thewriter = writer(f)\n",
    "    header = []\n",
    "    for columna in range(columnas):\n",
    "        texto = values[columna].text.strip()\n",
    "        header.append(texto)\n",
    "    thewriter.writerow(header)                                                                                                                             \n",
    "    for fila in range(num_filas-1):\n",
    "        datos_fila = []  # Crea una lista vacía para los datos de la fila actual\n",
    "        for columna in range(columnas):\n",
    "            try:\n",
    "                spans = filas[fila+1].find_all('span', {'class': 'ng-star-inserted'})\n",
    "                texto = spans[columna].text.strip()\n",
    "                texto = texto.replace(\"S/\", \"\").replace(\"US$\", \"\").replace(\"%\", \"\")\n",
    "                datos_fila.append(texto)  # Agrega el valor de datos a la lista de datos de la fila actual\n",
    "            except:\n",
    "                tds = filas[fila+1].find_all('td', {'class': 'ng-star-inserted'})\n",
    "                texto = tds[columna].text.strip()\n",
    "                texto = texto.replace(\"S/\", \"\").replace(\"US$\", \"\").replace(\"%\", \"\")\n",
    "                datos_fila.append(texto)  # Agrega el valor de datos a la lista de datos de la fila actual\n",
    "        thewriter.writerow(datos_fila)  # Escribe la lista de datos de la fila actual al archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS MOVIMIENTOS DIARIOS DE LA BVL ########\n",
    "\n",
    "#2da opción: Guardar los datos en un XLSX\n",
    "# Crear un archivo de Excel nuevo\n",
    "workbook = openpyxl.Workbook()\n",
    "\n",
    "# Seleccionar la primera hoja\n",
    "sheet = workbook.active\n",
    "\n",
    "# Crear los encabezados\n",
    "header = []\n",
    "for columna in range(columnas):\n",
    "    texto = values[columna].text.strip()\n",
    "    header.append(texto)\n",
    "\n",
    "# Agregar los encabezados a la primera fila de la hoja\n",
    "sheet.append(header)\n",
    "\n",
    "# Obtener los datos de las filas restantes y agregarlos al archivo de Excel\n",
    "for fila in range(num_filas-1):\n",
    "    fila_datos = []\n",
    "    for columna in range(columnas):\n",
    "        try:\n",
    "            spans = filas[fila+1].find_all('span', {'class': 'ng-star-inserted'})\n",
    "            texto = spans[columna].text.strip()\n",
    "            texto = texto.replace(\"S/\", \"\").replace(\"US$\", \"\").replace(\"%\", \"\")\n",
    "            fila_datos.append(texto)\n",
    "        except:\n",
    "            tds = filas[fila+1].find_all('td', {'class': 'ng-star-inserted'})\n",
    "            texto = tds[columna].text.strip()\n",
    "            texto = texto.replace(\"S/\", \"\").replace(\"US$\", \"\").replace(\"%\", \"\")\n",
    "            fila_datos.append(texto)\n",
    "    sheet.append(fila_datos)\n",
    "\n",
    "# Guardar el archivo de Excel\n",
    "workbook.save('Daily_Movements_BVL.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8887a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS MOVIMIENTOS DIARIOS DE LA BVL ########\n",
    "\n",
    "#3era opción: Guardar los datos en un DataFrame\n",
    "#Esta opción se puede facilitar al tener los anteriores documentos creados\n",
    "#Solo sería necesario leerlos con la librería pandas\n",
    "\n",
    "# Leer archivo CSV y crear DataFrame\n",
    "#df_csv = pd.read_csv('Daily_Movements_BVL.csv')\n",
    "\n",
    "# Leer archivo XLSX y crear DataFrame\n",
    "#df_xlsx = pd.read_excel('Daily_Movements_BVL.xlsx')\n",
    "\n",
    "#Caso desde cero\n",
    "# Crear un DataFrame vacío con las columnas correspondientes\n",
    "header = []\n",
    "for columna in range(columnas):\n",
    "    texto = values[columna].text.strip()\n",
    "    header.append(texto)\n",
    "df = pd.DataFrame(columns=header)\n",
    "\n",
    "# Agregar los datos al DataFrame\n",
    "data_frames = []\n",
    "for fila in range(num_filas-1):\n",
    "    datos_fila = {}  # Crea un diccionario vacío para los datos de la fila actual\n",
    "    for columna in range(columnas):\n",
    "        try:\n",
    "            spans = filas[fila+1].find_all('span', {'class': 'ng-star-inserted'})\n",
    "            texto = spans[columna].text.strip()\n",
    "            texto = texto.replace(\"S/\", \"\").replace(\"US$\", \"\").replace(\"%\", \"\")\n",
    "            datos_fila[header[columna]] = texto  # Agrega el valor de datos al diccionario de la fila actual\n",
    "        except:\n",
    "            tds = filas[fila+1].find_all('td', {'class': 'ng-star-inserted'})\n",
    "            texto = tds[columna].text.strip()\n",
    "            texto = texto.replace(\"S/\", \"\").replace(\"US$\", \"\").replace(\"%\", \"\")\n",
    "            datos_fila[header[columna]] = texto  # Agrega el valor de datos al diccionario de la fila actual\n",
    "    data_frames.append(pd.DataFrame.from_dict(datos_fila, orient='index').T)\n",
    "df = pd.concat(data_frames, ignore_index=True)  # Concatena todos los DataFrames individuales\n",
    "\n",
    "\n",
    "# En caso que se quiera guardar el DataFrame en un archivo Excel\n",
    "#df.to_excel('Dataframe_BVL.xlsx', index=False)\n",
    "\n",
    "#Observar los primeros 5 datos\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS ESTADOS FINANCIEROS DE EMPRESAS PERUANA DE LA BVL ########\n",
    "\n",
    "#Se obtienen los Estados Financieros de las empresas listadas en la BVL y que se elija\n",
    "#Primero obtener los enlaces que contienen la información financiera\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import time\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# Inicializar el controlador de Selenium\n",
    "driver = webdriver.Chrome('/path/to/chromedriver') # Reemplazar con la ruta al controlador de Chrome\n",
    "\n",
    "# Abrir la página web\n",
    "url = \"https://www.bvl.com.pe/mercado/movimientos-diarios\"\n",
    "driver.get(url)\n",
    "\n",
    "# Esperar a que cargue la página, 10 segundos es prudente\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"table-dark\")))\n",
    "\n",
    "# Obtener el HTML de la página\n",
    "html = driver.page_source\n",
    "\n",
    "# Analizar el HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Encontrar la tabla en el HTML\n",
    "tabla = soup.find(\"table\", {\"class\": \"table-dark\"})\n",
    "\n",
    "# Imprimir la tabla\n",
    "#print(tabla)\n",
    "\n",
    "#Obtenemos las filas dentro de la tabla y el número\n",
    "time.sleep(5) # Pausa de 5 segundos\n",
    "filas = tabla.find_all('tr', {'class': 'bvl-row'})\n",
    "#print(filas) #se puede imprimir el html en caso de querer revisarlo\n",
    "num_filas=len(filas)-1\n",
    "#print(num_filas)\n",
    "\n",
    "#Extraer el html donde se encuentran la información adicional de las acciones\n",
    "extra_info = tabla.find_all('tr', {'class': 'details-row'})\n",
    "#print(extra_info[0])\n",
    "\n",
    "\n",
    "# Encontrar todos los elementos li que contienen un enlace con el título \"Información financiera\"\n",
    "informacion_financiera = []\n",
    "for fila in range(num_filas-1):\n",
    "    li_list = extra_info[fila].find_all('li', {'class': 'ng-star-inserted'})\n",
    "    time.sleep(2)\n",
    "    for li in li_list:\n",
    "        a = li.find('a', {'title': 'Información financiera'})\n",
    "        time.sleep(2)\n",
    "        if a is not None:\n",
    "            informacion_financiera.append(a['href'])\n",
    "\n",
    "# Imprimir los enlaces obtenidos\n",
    "print(informacion_financiera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3654df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS ESTADOS FINANCIEROS DE EMPRESAS PERUANAS DE LA BVL ########\n",
    "\n",
    "#Enlazamos los links a la empresa correspondiente (nombre de la empresa y símbolo de la acción)\n",
    "empresas = {}  # Diccionario vacío para guardar la información\n",
    "\n",
    "for url in informacion_financiera:\n",
    "    # Inicializar el controlador de Selenium\n",
    "    driver = webdriver.Chrome('/path/to/chromedriver') # Reemplazar con la ruta al controlador de Chrome\n",
    "\n",
    "    # Abrir la página web\n",
    "    driver.get(url)\n",
    "\n",
    "    # Esperar a que cargue la página, 10 segundos es prudente\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # Obtener el HTML de la página\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Analizar el HTML con BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Obtener el nombre de la empresa\n",
    "    company_name = soup.find('h1', {'id': 'company-name'}).text.strip()\n",
    "    #print(company_name)\n",
    "\n",
    "    # Obtener el acrónimo de la acción\n",
    "    div_element = soup.find('div', {'class': 'g-site-select--label g-site-select--label--large'})\n",
    "    symbol = div_element.span.text\n",
    "\n",
    "    #print(symbol)\n",
    "\n",
    "    # Agregar la información al diccionario\n",
    "    empresas[url] = {'nombre': company_name, 'simbolo': symbol}\n",
    "\n",
    "    driver.quit() #Cerrar el navegador\n",
    "    time.sleep(2)\n",
    "    \n",
    "print(empresas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a312bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS ESTADOS FINANCIEROS DE EMPRESAS PERUANAS DE LA BVL ########\n",
    "\n",
    "#Elija las empresas de la que desea buscar su Información Financiera\n",
    "#Se obtienen los nombres, símbolo de la acción y los links\n",
    "#Asegúrese de seguir las instrucciones\n",
    "#Las listas (ya sea de nombres o símbolos) puedes utilizarlo para realizar la búsqueda\n",
    "#Toma en cuenta que es una búsqueda exacta (referencia al anterior comentario)\n",
    "\n",
    "#Creando la función de búsqueda\n",
    "def buscar_empresas():\n",
    "    empresas_seleccionadas = {}\n",
    "    contador=1\n",
    "    while True:\n",
    "        opcion_busqueda = input(\"¿Desea buscar por nombre o por símbolo? Escriba N para buscar por nombre o S para buscar por símbolo: \")\n",
    "        if opcion_busqueda.upper() == 'N':\n",
    "            opcion_lista = input(\"¿Desea ver la lista de nombres de empresas? Escriba S para sí o N para no: \")\n",
    "            if opcion_lista.upper() == 'S':\n",
    "                print(\"Lista de empresas:\")\n",
    "                for empresa in sorted(empresas.values(), key=lambda x: x['nombre']):\n",
    "                    print(\"- \" + empresa['nombre'])\n",
    "            nombre_empresa = input(\"Escriba el nombre de la empresa que desea buscar: \")\n",
    "            empresas_encontradas = [url_empresa for url_empresa, datos_empresa in empresas.items() if datos_empresa['nombre'] == nombre_empresa.upper()]\n",
    "            while len(empresas_encontradas) > 1:\n",
    "                print(\"Se encontraron varias empresas con el mismo nombre, por favor indique el símbolo de la empresa que desea buscar:\")\n",
    "                opcion_lista_simbolos = input(\"¿Desea ver la lista de símbolos de empresas? Escriba S para sí o N para no: \")\n",
    "                if opcion_lista_simbolos.upper() == 'S':\n",
    "                    print(\"Lista de símbolos de empresas:\")\n",
    "                    for empresa in sorted(empresas.values(), key=lambda x: x['nombre']):\n",
    "                        print(\"- \" + empresa['nombre'])\n",
    "                simbolo_empresa = input(\"Escriba el símbolo de la empresa que desea buscar: \")\n",
    "                empresas_encontradas = [url_empresa for url_empresa, datos_empresa in empresas.items() if datos_empresa['nombre'] == nombre_empresa and datos_empresa['simbolo'] == simbolo_empresa.upper()]\n",
    "            if len(empresas_encontradas) == 0:\n",
    "                print(\"No se encontró la empresa.\")\n",
    "            else:\n",
    "                print(\"Puedes encontrar información financiera de la empresa en el siguiente link:\", empresas_encontradas[0])\n",
    "                empresa_encontrada = empresas_encontradas[0]\n",
    "                datos_empresa = empresas[empresa_encontrada]\n",
    "                numero_empresa= empresas_encontradas[0]\n",
    "                numero_empresa = 'empresa' + str(contador)\n",
    "                datos_empresa_seleccionada = {'nombre': datos_empresa['nombre'], 'simbolo': datos_empresa['simbolo'], 'link':empresas_encontradas[0]}\n",
    "                empresas_seleccionadas[numero_empresa] = datos_empresa_seleccionada\n",
    "                contador += 1\n",
    "        elif opcion_busqueda.upper() == 'S':\n",
    "            opcion_lista = input(\"¿Desea ver la lista de símbolos de empresas? Escriba S para sí o N para no: \")\n",
    "            if opcion_lista.upper() == 'S':\n",
    "                print(\"Lista de símbolos de empresas:\")\n",
    "                for empresa in empresas.values():\n",
    "                    print(\"- \" + empresa['simbolo'])\n",
    "            simbolo_empresa = input(\"Escriba el símbolo de la empresa que desea buscar: \")\n",
    "            empresas_encontradas = [url_empresa for url_empresa, datos_empresa in empresas.items() if datos_empresa['simbolo'] == simbolo_empresa.upper()]\n",
    "            if len(empresas_encontradas) == 0:\n",
    "                print(\"No se encontró la empresa.\")\n",
    "            else:\n",
    "                print(\"Puedes encontrar información financiera de la empresa en el siguiente link:\", empresas_encontradas[0])\n",
    "                empresa_encontrada = empresas_encontradas[0]\n",
    "                datos_empresa = empresas[empresa_encontrada]\n",
    "                numero_empresa= empresas_encontradas[0]\n",
    "                numero_empresa = 'empresa' + str(contador)\n",
    "                datos_empresa_seleccionada = {'nombre': datos_empresa['nombre'], 'simbolo': datos_empresa['simbolo'], 'link':empresas_encontradas[0]}\n",
    "                empresas_seleccionadas[numero_empresa] = datos_empresa_seleccionada\n",
    "                contador += 1\n",
    "\n",
    "        else:\n",
    "            print(\"Opción no válida.\")\n",
    "\n",
    "        opcion_continuar = input(\"¿Desea continuar con la búsqueda? Escriba S para sí o N para no: \")\n",
    "        if opcion_continuar.upper() == 'N':\n",
    "            print(\"\\n\")\n",
    "            print(\"Estas son las empresas seleccionadas:\")\n",
    "            print(empresas_seleccionadas)\n",
    "            return empresas_seleccionadas\n",
    "            break\n",
    "            \n",
    "#Ejecutar la función de búsqueda y guardarla\n",
    "empresas_seleccionadas= buscar_empresas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26916ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WEB SCRAPING DE LOS ESTADOS FINANCIEROS DE EMPRESAs PERUANAs DE LA BVL ########\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from csv import writer\n",
    "import time\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import datetime\n",
    "\n",
    "enlaces = [empresa['link'] for empresa in empresas_seleccionadas.values()]\n",
    "nombres = [empresa['nombre'] for empresa in empresas_seleccionadas.values()] #VOLCAN COMPAÑIA MINERA S.A.A. #ALICORP S.A.A.\n",
    "#Año_actual= datetime.datetime.now().year #Comienza desde 2023\n",
    "\n",
    "# Crea un objeto de libro de trabajo\n",
    "#libro = openpyxl.Workbook()\n",
    "\n",
    "for i, url in enumerate(enlaces):\n",
    "    driver = webdriver.Chrome(executable_path=r\"C:\\Users\\Administrador\\Desktop\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(3)\n",
    "    driver.execute_script(\"window.scrollBy(0, 525);\")\n",
    "    \n",
    "    Año_actual= datetime.datetime.now().year #Comienza desde 2023\n",
    "    \n",
    "    actions = ActionChains(driver)\n",
    "    boton_cookie=driver.find_element(By.XPATH, '/html/body/bvl-root/bvl-main-layout/bvl-footer/footer/bvl-cookies-banner/div/div/div/div[2]/button')\n",
    "    boton_cookie.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Seleccionar el Periodo\n",
    "    time.sleep(3)\n",
    "    periodo = driver.find_element(By.XPATH, '//*[@id=\"page-view\"]/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/bvl-toolbar/div/div[2]/div/div[1]')\n",
    "    time.sleep(2)\n",
    "    anual = driver.find_element(By.XPATH, '//*[@id=\"page-view\"]/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/bvl-toolbar/div/div[2]/div/div[2]/div[2]')\n",
    "    time.sleep(3)\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(periodo).move_to_element(anual).click().perform()\n",
    "    \n",
    "    #Mover el cursor a filtro Año    \n",
    "    año = driver.find_element(By.XPATH, '//*[@id=\"page-view\"]/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/bvl-toolbar/div/div[3]/div/div[1]')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    libro = openpyxl.Workbook()\n",
    "    \n",
    "    #Se pregunta la cantidad de años que desea extraer, Ejm: 2018-2020 es 3\n",
    "    while True:\n",
    "        try:\n",
    "            numero_años = int(input(\"Ingrese el número de años que desea obtener: \"))\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Número inválido. Por favor, ingrese un número entero válido.\")   \n",
    "            \n",
    "    verificador=numero_años\n",
    "    #print(\"verificador inicial es \", verificador)\n",
    "    \n",
    "    año_actual=1 #1 es el año más actual, 2 el año anterior y así sucesivamente\n",
    "    \n",
    "    while verificador>0:\n",
    "    #for año in range(1, numero_años+1):     \n",
    "        #print(existe_informacion)\n",
    "            \n",
    "        año = driver.find_element(By.XPATH, '//*[@id=\"page-view\"]/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/bvl-toolbar/div/div[3]/div/div[1]')\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #for año in range(1, numero_años)\n",
    "        \n",
    "        #Seleccionamos el año\n",
    "        año_elegido = driver.find_element(By.XPATH, \"//*[@id='page-view']/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/bvl-toolbar/div/div[3]/div/div[2]/div[\"+str(año_actual)+\"]\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #Siguiente año que se revisará\n",
    "        #año_actual = año_actual+1\n",
    "        \n",
    "        #Seleccionando filtro año\n",
    "        if año_actual==1:\n",
    "            actions.move_to_element(año).click()\n",
    "            time.sleep(2) \n",
    "        else:\n",
    "            actions.move_to_element(año).move_to_element(año_elegido).click().perform()\n",
    "            time.sleep(3)\n",
    "            \n",
    "        #print(año_actual)    \n",
    "        #Siguiente año que se revisará\n",
    "        año_actual = año_actual + 1\n",
    "        #print(año_actual)         \n",
    "        \n",
    "        try:\n",
    "            existe_informacion =driver.find_element(By.XPATH, \"//*[@id='page-view']/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/section/bvl-section-header/header/div[1]/h1\")             \n",
    "        except NoSuchElementException:\n",
    "            existe_informacion = None\n",
    "        \n",
    "        #print(\"La informacion es \", existe_informacion)   \n",
    "                \n",
    "        if existe_informacion is not None:\n",
    "            \n",
    "            #Abrimos un libro de Excel donde se almacenará la información\n",
    "            #libro = openpyxl.Workbook()\n",
    "            #libro.close()\n",
    "            \n",
    "            #Contador que ayuda a verificar la cantidad de años extraídos\n",
    "            verificador -= 1\n",
    "            #print(\"Verificador es:\", verificador)\n",
    "            #Año_actual = Año_actual-1\n",
    "            \n",
    "            #Seleccionar Estado Financiero:\n",
    "            #Elegimos los estados principales (si desea otra información, puede automatizar o cambiar valores)\n",
    "            Estado_Situacion_Financiera = '//*[@id=\"page-view\"]/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/section/bvl-table-file-link/table/tbody/tr[1]/td[1]/a'\n",
    "            Estado_Resultados='//*[@id=\"page-view\"]/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/section/bvl-table-file-link/table/tbody/tr[2]/td[1]/a'\n",
    "            Estado_Flujos_Efectivo='//*[@id=\"page-view\"]/main/section/bvl-issuer-details/div/div/bvl-tabs/bvl-tab[5]/div/div[2]/bvl-resources/section/bvl-table-file-link/table/tbody/tr[5]/td[1]/a'\n",
    "            \n",
    "            #Almacenamos los estados financieros seleccionados\n",
    "            Estados_Financieros={Estado_Situacion_Financiera:'SituacionFinanciera' , \n",
    "                                 Estado_Resultados:'Resultados' , \n",
    "                                 Estado_Flujos_Efectivo:'FlujoEfectivo' \n",
    "                                }\n",
    "            \n",
    "            #Acá comienza lo diferente, la reestructuración del código\n",
    "\n",
    "            #Finalmente obtenemos la información de cada estado\n",
    "            for estados, nombre_estado in Estados_Financieros.items():\n",
    "                #Seleccionar el Estado Financiero\n",
    "                click_button=driver.find_element(By.XPATH, estados)\n",
    "                time.sleep(3)\n",
    "                click_button.click()\n",
    "                time.sleep(2)\n",
    "\n",
    "                #Expandir la tabla\n",
    "                expand_button = driver.find_element(By.XPATH, '/html/body/bvl-shared-modal/div/div/div/div[1]/div[2]/button/i')\n",
    "                expand_button.click()\n",
    "\n",
    "                #Obteniendo el número de filas y columnas de la tabla\n",
    "                time.sleep(1)\n",
    "                rows = len(driver.find_elements(By.XPATH, '/html/body/bvl-shared-modal/div/div/div/div[2]/bvl-dynamic-table/div[2]/table/tbody/tr'))\n",
    "                col =  len(driver.find_elements(By.XPATH, '/html/body/bvl-shared-modal/div/div/div/div[2]/bvl-dynamic-table/div[2]/table/tbody/tr[1]/td'))\n",
    "                time.sleep(2)\n",
    "                #print(rows) #77\n",
    "                #print(col) #4\n",
    "                \n",
    "                \n",
    "                # Crea una nueva hoja con el nombre de la empresa y el año correspondiente\n",
    "                hoja_nombre = nombre_estado + str(Año_actual)\n",
    "                #Año_actual = Año_actual-1\n",
    "                hoja = libro.create_sheet(hoja_nombre)\n",
    "                encabezado = driver.find_elements(By.XPATH, '/html/body/bvl-shared-modal/div/div/div/div[2]/bvl-dynamic-table/div[2]/table/tbody/tr[1]/td')\n",
    "                header = [elem.text for elem in encabezado]\n",
    "                hoja.append(header)\n",
    "\n",
    "                data=[]\n",
    "                fila=[]\n",
    "\n",
    "                rows = len(driver.find_elements(By.XPATH, '/html/body/bvl-shared-modal/div/div/div/div[2]/bvl-dynamic-table/div[2]/table/tbody/tr'))\n",
    "                col =  len(driver.find_elements(By.XPATH, '/html/body/bvl-shared-modal/div/div/div/div[2]/bvl-dynamic-table/div[2]/table/tbody/tr[1]/td'))\n",
    "                time.sleep(2)\n",
    "                for n in range(2, rows+1):\n",
    "                    fila = []\n",
    "                    for b in range(1, col+1):\n",
    "                        dato = driver.find_element(By.XPATH, \"/html/body/bvl-shared-modal/div/div/div/div[2]/bvl-dynamic-table/div[2]/table/tbody/tr[\"+str(n)+\"]/td[\"+str(b)+\"]\")\n",
    "                        #time.sleep(1)\n",
    "                        #fila.append(dato.text)\n",
    "                        #fila.append(dato.get_attribute(\"textContent\"))\n",
    "                        fila.append(dato.get_attribute(\"innerHTML\"))\n",
    "                        \n",
    "                    hoja.append(fila)\n",
    "                \n",
    "                #Botón cerrar tabla\n",
    "                close_button = driver.find_element(By.XPATH, '/html/body/bvl-shared-modal/div/div/div/div[1]/button')\n",
    "                close_button.click()\n",
    "                \n",
    "                fila=[]\n",
    "                time.sleep(2)\n",
    "\n",
    "                # Guarda el archivo de Excel con el nombre de la empresa\n",
    "                #archivo_excel = nombres[i] + \".xlsx\"\n",
    "                #libro.save(archivo_excel)\n",
    "                \n",
    "            Año_actual = Año_actual-1\n",
    "     \n",
    "        else:  \n",
    "            Año_actual = Año_actual-1\n",
    "            print()\n",
    "        #print(\"numero es\", numero_años)\n",
    "            continue\n",
    "            \n",
    "        archivo_excel = nombres[i] + \".xlsx\"\n",
    "        libro.save(archivo_excel)\n",
    "        #libro.close()\n",
    "        \n",
    "    # Cerrar el controlador de Selenium\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
